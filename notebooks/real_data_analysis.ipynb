{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from counterfactualEO import *\n",
    "import joblib\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.special import expit, logit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_nuisance(train, test, A, X, R, D, Y, learner_pi, learner_mu,\n",
    "                   trunc_pi=0.975):\n",
    "    \"\"\"Train nuisance regressions.\"\"\"\n",
    "    train = train.reset_index()\n",
    "    test = test.reset_index()\n",
    "    # pred_cols = list(itertools.chain.from_iterable([A, X, R]))\n",
    "    pred_cols = [A] + X + [R]\n",
    "    learner_pi.fit(train[pred_cols], train[D])\n",
    "    learner_mu.fit(train.loc[train[D].eq(0), pred_cols],\n",
    "                   train.loc[train[D].eq(0), Y])\n",
    "    if hasattr(learner_pi, 'predict_proba'):\n",
    "        pihat = pd.Series(learner_pi.predict_proba(test[pred_cols])[:, 1],\n",
    "                          name='pihat').clip(upper=trunc_pi)\n",
    "    else:\n",
    "        pihat = pd.Series(learner_pi.predict(test[pred_cols]),\n",
    "                          name='pihat').clip(upper=trunc_pi)\n",
    "    if hasattr(learner_mu, 'predict_proba'):\n",
    "        muhat0 = pd.Series(learner_mu.predict_proba(test[pred_cols])[:, 1],\n",
    "                           name='muhat0')\n",
    "    else:\n",
    "        muhat0 = pd.Series(learner_mu.predict(test[pred_cols]), name='muhat0')\n",
    "    phihat = pd.Series(\n",
    "        (1 - test[D]) / (1 - pihat) * (test[Y] - muhat0) + muhat0,\n",
    "        name='phihat')\n",
    "\n",
    "    out = pd.concat([pihat, muhat0, phihat], axis=1)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "#########################\n",
    "#### Risk functions #####\n",
    "#########################\n",
    "\n",
    "def risk_coef(data, a, r, A='A', R='R', outcome='phihat'):\n",
    "    \"\"\"Compute the loss coefficient for a single row, for given values\n",
    "    A = a, R = r.\n",
    "\n",
    "    Using phihat as the outcome yields a doubly robust estimator.\n",
    "    Using muhat0 as the outcome yields a plugin estimator.\n",
    "    Using mu0 as the outcome yields (something close to) the ``true'' loss\n",
    "    coefficient.\n",
    "    \"\"\"\n",
    "    out = (((data[A] == a) & (data[R] == r)) * (1 - 2 * data[outcome])).mean()\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def risk_coefs(data, A='A', R='R', outcome='phihat'):\n",
    "    \"\"\"Compute the loss coefficients.\n",
    "\n",
    "    Using phihat as the outcome yields a doubly robust estimator.\n",
    "    Using muhat0 as the outcome yields a plugin estimator.\n",
    "    Using mu0 as the outcome yields (something close to) the ``true'' loss\n",
    "    coefficients.\n",
    "    \"\"\"\n",
    "    ar_list = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "    coefs = [risk_coef(data, a, r, A, R, outcome) for a, r in ar_list]\n",
    "    out = np.array(coefs).clip(-1, 1)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "###############################\n",
    "#### Error rate functions #####\n",
    "###############################\n",
    "\n",
    "# def cFPR(data, R, outcome='phihat'):\n",
    "#     \"\"\"Compute estimated counterfactual False Positive Rate.\"\"\"\n",
    "#     return (data[R]*(1 - data[outcome])).mean() / (1 - data[outcome]).mean()\n",
    "\n",
    "# def cFPR(data, A, R, outcome):\n",
    "#     \"\"\"Compute estimated group-specific counterfactual False Positive Rate.\"\"\"\n",
    "#     return data.groupby(A).apply(_cFPR, R, outcome).values\n",
    "\n",
    "# def cFNR(data, R, outcome='phihat'):\n",
    "#     \"\"\"Compute estimated counterfactual False Positive Rate.\"\"\"\n",
    "#     return ((1 - data[R])*data[outcome]).mean() / data[outcome].mean()\n",
    "\n",
    "# def cFNR(data, A, R, outcome):\n",
    "#     \"\"\"Compute estimated group-specific counterfactual False Positive Rate.\"\"\"\n",
    "#     return data.groupby(A).apply(_cFNR, R, outcome).values\n",
    "\n",
    "def cFPR(data, R, outcome='phihat'):\n",
    "    \"\"\"Compute estimated counterfactual False Positive Rate.\"\"\"\n",
    "    out = data.eval(\"{}*(1 - {})\".format(R, outcome)).mean() / data.eval(\"1 - {}\".format(outcome)).mean()\n",
    "    return out\n",
    "\n",
    "def cFNR(data, R, outcome='phihat'):\n",
    "    \"\"\"Compute estimated counterfactual False Positive Rate.\"\"\"\n",
    "    out = data.eval(\"(1 - {})*{}\".format(R, outcome)).mean() / data.eval(\"{}\".format(outcome)).mean()\n",
    "    return out\n",
    "\n",
    "def fairness_coefs(data, A='A', R='R', outcome='phihat'):\n",
    "    \"\"\"Get coefficients that define the fairness constraints for the estimator.\"\"\"\n",
    "    false_pos = data.groupby(A).apply(cFPR, R, outcome).values.clip(0, 1)\n",
    "    false_neg = data.groupby(A).apply(cFNR, R, outcome).values.clip(0, 1)\n",
    "    coefs_pos = np.array(\n",
    "        [1 - false_pos[0], false_pos[0], false_pos[1] - 1, -false_pos[1]])\n",
    "    coefs_neg = np.array(\n",
    "        [-false_neg[0], false_neg[0] - 1, false_neg[1], 1 - false_neg[1]])\n",
    "\n",
    "    return (coefs_pos, coefs_neg)\n",
    "\n",
    "\n",
    "def optimize(risk_coefs, coefs_pos, coefs_neg, epsilon_pos, epsilon_neg):\n",
    "    \"\"\"Solve the LP.\"\"\"\n",
    "    theta = cp.Variable(4)\n",
    "    objective = cp.Minimize(risk_coefs @ theta)\n",
    "    constraints = [0 <= theta, theta <= 1,\n",
    "                   coefs_pos @ theta <= epsilon_pos,\n",
    "                   coefs_pos @ theta >= -epsilon_pos,\n",
    "                   coefs_neg @ theta <= epsilon_neg,\n",
    "                   coefs_neg @ theta >= -epsilon_neg]\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    result = prob.solve(solver=cp.ECOS_BB)\n",
    "\n",
    "    return theta.value  # , result\n",
    "\n",
    "\n",
    "#### Full optimization ####\n",
    "def fair_derived(data, A, X, R, D, Y, learner_pi, learner_mu, epsilon_pos,\n",
    "                 epsilon_neg, outcome='phihat', k=2, test_size=0.50, trunc_pi=0.975,\n",
    "                random_state = 42):\n",
    "    \"\"\"Optimization with chosen estimators for loss and fairness constraints.\n",
    "    \n",
    "    Args:\n",
    "      k: Number of folds to use for cross-fitting.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits = k, shuffle = True, random_state = random_state)\n",
    "    theta_arr = np.zeros((k, 4))\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        nuisance_fold, opt_fold = data.iloc[train_index], data.iloc[test_index]\n",
    "        # TODO: this next line is wrong. Not using the folds. Right?\n",
    "        data_nuisance, data_opt = train_test_split(data, test_size=test_size)\n",
    "        nuis = train_nuisance(data_nuisance, data_opt, A, X, R, D, Y, learner_pi,\n",
    "                              learner_mu, trunc_pi)\n",
    "        data_opt = pd.concat([data_opt.reset_index(), nuis.reset_index()], axis=1)\n",
    "        obj = risk_coefs(data_opt, A=A, R=R, outcome=outcome)\n",
    "        fair_pos, fair_neg = fairness_coefs(data_opt, A=A, R=R, outcome=outcome)\n",
    "        theta = optimize(obj, fair_pos, fair_neg, epsilon_pos, epsilon_neg)\n",
    "        theta_arr[i, :] = theta\n",
    "        i += 1\n",
    "        \n",
    "#     out = {'theta': theta, 'risk_coefs': obj,\n",
    "#            'fairness_coefs_pos': fair_pos, 'fairness_coefs_neg': fair_neg}\n",
    "#     return out\n",
    "    return theta_arr\n",
    "\n",
    "\n",
    "def indicator_df(df, A='A', R='R'):\n",
    "    \"\"\"Get four-column df indicating values of A and R in each row.\"\"\"\n",
    "    ar_list = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "    out_list = [((df[A] == a) & (df[R] == r)) for a, r in ar_list]\n",
    "    out = pd.DataFrame(np.array(out_list).T,\n",
    "                       columns = ['A0_R0', 'A0_R1', 'A1_R0', 'A1_R1'])\n",
    "    return out\n",
    "\n",
    "\n",
    "def ci_prob(est, sd, z, n, scale='logit'):\n",
    "    \"\"\"Compute a CI around a probability, either on the expit or the logit scale.\"\"\"\n",
    "    if (scale == 'logit') and (0 < est < 1):\n",
    "        sd = sd/(est*(1 - est))\n",
    "        lower = expit(logit(est) - z*sd/np.sqrt(n))\n",
    "        upper = expit(logit(est) + z*sd/np.sqrt(n))\n",
    "    else:\n",
    "        lower = max(0, est - z * sd / np.sqrt(n))\n",
    "        upper = min(est + z * sd / np.sqrt(n), 1)\n",
    "\n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "def ci_prob_diff(est, sd, z, n, scale='logit'):\n",
    "    \"\"\"Compute a CI around a difference of probabilities, either on the expit or the logit scale.\"\"\"\n",
    "    if (scale == 'logit') and (-1 < est < 1):\n",
    "        sd = sd*2/(1 - est**2)\n",
    "        lower = 2*(expit(logit(est/2 + 1/2) - z * sd / np.sqrt(n)) - 1/2)\n",
    "        upper = 2*(expit(logit(est/2 + 1/2) + z * sd / np.sqrt(n)) - 1/2)\n",
    "    else:\n",
    "        lower = max(-1, est - z * sd / np.sqrt(n))\n",
    "        upper = min(est + z * sd / np.sqrt(n), 1)\n",
    "\n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "def est_risk(theta, data, A='A', R='R', outcome='phihat', ci=0.95,\n",
    "             ci_scale='logit'):\n",
    "    \"\"\"Compute risk and risk change estimates, with optional CIs.\"\"\"\n",
    "    ind_df = indicator_df(data, A, R)\n",
    "\n",
    "    ## Risk and risk change point estimates\n",
    "    # influence function\n",
    "    inf_risk_pre = ind_df.dot([0, 1, 0, 1]) * (1 - 2 * data[outcome]) + data[\n",
    "        outcome]\n",
    "    inf_risk_post = ind_df.dot(theta) * (1 - 2 * data[outcome]) + data[outcome]\n",
    "    inf_change = inf_risk_post - inf_risk_pre\n",
    "\n",
    "    risk_est = min(max(0, inf_risk_post.mean()), 1)\n",
    "    change_est = min(max(-1, inf_change.mean()), 1)\n",
    "    out = {'metric': ['risk', 'risk_change'], 'value': [risk_est, change_est],\n",
    "           'ci_lower': [None] * 2, 'ci_upper': [None] * 2}\n",
    "\n",
    "    ## CIs\n",
    "    if ci:\n",
    "        z = scipy.stats.norm.ppf((ci + 1) / 2)\n",
    "        n = data.shape[0]\n",
    "        risk_sd = np.std(inf_risk_post)\n",
    "        change_sd = np.std(inf_change)\n",
    "        lower_risk, upper_risk = ci_prob(risk_est, risk_sd, z, n, ci_scale)\n",
    "        lower_change, upper_change = ci_prob_diff(change_est, change_sd, z, n, ci_scale)\n",
    "\n",
    "        # if (ci_scale == 'logit') and (0 < risk_est < 1):\n",
    "        #     risk_sd = np.std(inf_risk_post)/(risk_est*(1 - risk_est))\n",
    "        #     lower_risk = expit(logit(risk_est) - z * risk_sd / np.sqrt(n))\n",
    "        #     upper_risk = expit(logit(risk_est) + z * risk_sd / np.sqrt(n))\n",
    "        # else:\n",
    "        #     risk_sd = np.std(inf_risk_post)\n",
    "        #     lower_risk = max(0, risk_est - z * risk_sd / np.sqrt(n))\n",
    "        #     upper_risk = min(risk_est + z * risk_sd / np.sqrt(n), 1)\n",
    "        # if (ci_scale == 'logit') and (-1 < change_est < 1):\n",
    "        #     change_sd = np.std(inf_change)*2/(1 - change_est**2)\n",
    "        #     lower_change = 2*(expit(logit(change_est/2 + 1/2) - z * change_sd / np.sqrt(n))) - 1\n",
    "        #     upper_change = 2*(expit(logit(change_est/2 + 1/2) + z * change_sd / np.sqrt(n))) - 1\n",
    "        # else:\n",
    "        #     change_sd = np.std(inf_change)\n",
    "        #     lower_change = max(-1, change_est - z * change_sd / np.sqrt(n))\n",
    "        #     upper_change = min(change_est + z * change_sd / np.sqrt(n), 1)\n",
    "\n",
    "        out['ci_lower'] = [lower_risk, lower_change]\n",
    "        out['ci_upper'] = [upper_risk, upper_change]\n",
    "\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "\n",
    "# def est_risk(theta, data, A='A', R='R', outcome='phihat', ci=0.95):\n",
    "#     \"\"\"Compute risk and risk change estimates, with optional CIs.\"\"\"\n",
    "#     ind_df = indicator_df(data, A, R)\n",
    "#\n",
    "#     ## Risk and risk change point estimates\n",
    "#     # influence function\n",
    "#     inf_risk_pre = ind_df.dot([0, 1, 0, 1]) * (1 - 2 * data[outcome]) + data[\n",
    "#         outcome]\n",
    "#     inf_risk_post = ind_df.dot(theta) * (1 - 2 * data[outcome]) + data[outcome]\n",
    "#     inf_change = inf_risk_post - inf_risk_pre\n",
    "#\n",
    "#     risk_est = min(max(0, inf_risk_post.mean()), 1)\n",
    "#     change_est = min(max(-1, inf_change.mean()), 1)\n",
    "#     out = {'metric': ['risk', 'risk_change'], 'value': [risk_est, change_est],\n",
    "#            'ci_lower': [None] * 2, 'ci_upper': [None] * 2}\n",
    "#\n",
    "#     ## CIs\n",
    "#     if ci:\n",
    "#         z = scipy.stats.norm.ppf((ci + 1) / 2)\n",
    "#         n = data.shape[0]\n",
    "#         risk_sd = np.std(inf_risk_post)\n",
    "#         change_sd = np.std(inf_change)\n",
    "#\n",
    "#         lower_risk = max(0, risk_est - z * risk_sd / np.sqrt(n))\n",
    "#         upper_risk = min(risk_est + z * risk_sd / np.sqrt(n), 1)\n",
    "#         lower_change = max(-1, change_est - z * change_sd / np.sqrt(n))\n",
    "#         upper_change = min(change_est + z * change_sd / np.sqrt(n), 1)\n",
    "#\n",
    "#         out['ci_lower'] = [lower_risk, lower_change]\n",
    "#         out['ci_upper'] = [upper_risk, upper_change]\n",
    "#\n",
    "#     return pd.DataFrame(out)\n",
    "\n",
    "\n",
    "def est_cFPR(theta, data, A='A', R='R', outcome='phihat', ci=0.95,\n",
    "             ci_scale='logit'):\n",
    "    \"\"\"Estimate the cFPR and the fairness gap for one group.\n",
    "    \"\"\"\n",
    "    # Get the two vectors of IF values for the estimators.\n",
    "    # Compute all three estimates\n",
    "    # If CI, get the variance vectors for both groups. Compute all 3 variances.\n",
    "    ## cFPRs for the input predictor\n",
    "    coefs_pos, _ = fairness_coefs(data, A, R, outcome)\n",
    "    est0 = coefs_pos[:2] @ theta[:2]\n",
    "    est1 = abs(coefs_pos[2:] @ theta[2:])\n",
    "    est_diff = est0 - est1\n",
    "\n",
    "    out = {'metric': ['FPR0', 'FPR1', 'gap_FPR'],\n",
    "           'value': [est0, est1, est_diff]}\n",
    "    out['ci_lower'] = [None] * 3\n",
    "    out['ci_upper'] = [None] * 3\n",
    "\n",
    "    if ci:\n",
    "        n = data.shape[0]\n",
    "        z = scipy.stats.norm.ppf((ci + 1) / 2)\n",
    "        h0 = (1 - data[outcome]) * (1 - data[A])\n",
    "        h1 = (1 - data[outcome]) * data[A]\n",
    "        var_func0 = 1 / h0.mean() * (theta[1] - theta[0]) * (\n",
    "                    data[R] - est0) * h0\n",
    "        var_func1 = 1 / h1.mean() * (theta[3] - theta[2]) * (\n",
    "                    data[R] - est0) * h1\n",
    "        sd0 = np.std(var_func0)\n",
    "        sd1 = np.std(var_func1)\n",
    "        sd_diff = np.std(var_func0 - var_func1)\n",
    "\n",
    "        lower0, upper0 = ci_prob(est0, sd0, z, n, ci_scale)\n",
    "        lower1, upper1 = ci_prob(est1, sd1, z, n, ci_scale)\n",
    "        lower_diff, upper_diff = ci_prob_diff(est_diff, sd_diff, z, n, ci_scale)\n",
    "        # lower0 = max(0, est0 - z * sd0 / np.sqrt(n))\n",
    "        # upper0 = min(est0 + z * sd0 / np.sqrt(n), 1)\n",
    "        # lower1 = max(0, est1 - z * sd1 / np.sqrt(n))\n",
    "        # upper1 = min(est1 + z * sd1 / np.sqrt(n), 1)\n",
    "        # lower_diff = max(-1, est_diff - z * sd_diff / np.sqrt(n))\n",
    "        # upper_diff = min(est_diff + z * sd_diff / np.sqrt(n), 1)\n",
    "\n",
    "        out['ci_lower'] = [lower0, lower1, lower_diff]\n",
    "        out['ci_upper'] = [upper0, upper1, upper_diff]\n",
    "\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "\n",
    "def est_cFNR(theta, data, A='A', R='R', outcome='phihat', ci=0.95,\n",
    "             ci_scale='logit'):\n",
    "    \"\"\"Estimate the cFNR and the fairness gap for one group.\n",
    "    \"\"\"\n",
    "    # Get the two vectors of IF values for the estimators.\n",
    "    # Compute all three estimates\n",
    "    # If CI, get the variance vectors for both groups. Compute all 3 variances.\n",
    "    ## cFPRs for the input predictor\n",
    "    _, coefs_neg = fairness_coefs(data, A, R, outcome)\n",
    "    est0 = coefs_neg[:2] @ theta[:2] + 1\n",
    "    est1 = 1 - coefs_neg[2:] @ theta[2:]\n",
    "    est_diff = est0 - est1\n",
    "\n",
    "    out = {'metric': ['FNR0', 'FNR1', 'gap_FNR'],\n",
    "           'value': [est0, est1, est_diff]}\n",
    "    out['ci_lower'] = [None] * 3\n",
    "    out['ci_upper'] = [None] * 3\n",
    "\n",
    "    if ci:\n",
    "        n = data.shape[0]\n",
    "        z = scipy.stats.norm.ppf((ci + 1) / 2)\n",
    "        h0 = data[outcome] * (1 - data[A])\n",
    "        h1 = data[outcome] * data[A]\n",
    "        var_func0 = 1 / h0.mean() * (theta[1] - theta[0]) * (\n",
    "                    data[R] - est0) * h0\n",
    "        var_func1 = 1 / h1.mean() * (theta[3] - theta[2]) * (\n",
    "                    data[R] - est0) * h1\n",
    "        var_func_diff = var_func0 - var_func1\n",
    "        sd0 = np.std(var_func0)\n",
    "        sd1 = np.std(var_func1)\n",
    "        sd_diff = np.std(var_func0 - var_func1)\n",
    "\n",
    "        lower0, upper0 = ci_prob(est0, sd0, z, n, ci_scale)\n",
    "        lower1, upper1 = ci_prob(est1, sd1, z, n, ci_scale)\n",
    "        lower_diff, upper_diff = ci_prob_diff(est_diff, sd_diff, z, n, ci_scale)\n",
    "\n",
    "        # lower0 = max(0, est0 - z * sd0 / np.sqrt(n))\n",
    "        # upper0 = min(est0 + z * sd0 / np.sqrt(n), 1)\n",
    "        # lower1 = max(0, est1 - z * sd1 / np.sqrt(n))\n",
    "        # upper1 = min(est1 + z * sd1 / np.sqrt(n), 1)\n",
    "        # lower_diff = max(-1, est_diff - z * sd_diff / np.sqrt(n))\n",
    "        # upper_diff = min(est_diff + z * sd_diff / np.sqrt(n), 1)\n",
    "\n",
    "        out['ci_lower'] = [lower0, lower1, lower_diff]\n",
    "        out['ci_upper'] = [upper0, upper1, upper_diff]\n",
    "\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "\n",
    "# def _est_cFPR(theta, data, A='A', R='R', outcome='phihat', ci='None'):\n",
    "#     \"\"\"Estimate the cFPR and the fairness gap for one group.\"\"\"\n",
    "#     inf_func = (data[R]*(1 - data[outcome])).mean() / (1 - data[outcome])\n",
    "#     est = inf_func.mean()\n",
    "#     out = {'est': est, 'ci_lower': None, 'ci_upper': None}\n",
    "#     if ci:\n",
    "#         z = scipy.stats.norm.ppf((ci + 1)/2)\n",
    "#         sd = np.sd(inf_func)\n",
    "#         n = data.shape[0]\n",
    "#         ci_lower = est - z*sd/np.sqrt(n)\n",
    "#         ci_upper = est + z*sd/np.sqrt(n)\n",
    "#         out['ci_lower'] = ci_lower\n",
    "#         out['ci_upper'] = ci_upper\n",
    "#\n",
    "#     return out\n",
    "#\n",
    "#\n",
    "# def est_cFPR(theta, data, A='A', R='R', outcome='phihat', ci='None'):\n",
    "#     \"\"\"Estimate the cFPR and the fairness gap.\"\"\"\n",
    "#     inf_func = data.groupby(A).apply(_est_cFPR)\n",
    "#     pass\n",
    "\n",
    "\n",
    "#### metrics: for a fixed post-processed predictor ####\n",
    "def metrics(theta, data, A, X, R, D, Y, learner_pi, learner_mu, \n",
    "            outcome='phihat', k=2, ci=0.95, ci_scale='logit', random_state=42):\n",
    "    \"\"\"Compute risk and fairness metrics wrt Y0.\n",
    "\n",
    "    Args:\n",
    "      data: data over which to compute the metrics.\n",
    "      outcome:\n",
    "        Using phihat as the outcome yields doubly robust estimators.\n",
    "        Using muhat0 as the outcome yields plugin estimators.\n",
    "        Using mu0 as the outcome yields (desomething close to) the true metrics.\n",
    "      k: Number of folds to use for cross-fitting.\n",
    "      ci: Either None, in which case no CI is computed, or a value in (0, 1).\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits = k, shuffle = True, random_state = random_state)\n",
    "    theta_arr = np.zeros((k, 4))\n",
    "    i = 0\n",
    "    out = []\n",
    "    nuis_all = pd.DataFrame(np.zeros((data.shape[0], 3)))\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        data_nuisance, data_opt = data.iloc[train_index], data.iloc[test_index]\n",
    "        nuis = train_nuisance(data_nuisance, data_opt, A, X, R, D, Y, learner_pi, learner_mu)\n",
    "        nuis_all.iloc[test_index] = nuis.copy().values\n",
    "        data_opt = pd.concat([data_opt.reset_index(), nuis.reset_index()], axis=1)\n",
    "        out.append(est_risk(theta, data_opt, A=A, R=R, outcome=outcome, ci=False))\n",
    "        out.append(est_cFPR(theta, data_opt, A=A, R=R, outcome=outcome, ci=False))\n",
    "        out.append(est_cFNR(theta, data_opt, A=A, R=R, outcome=outcome, ci=False))\n",
    "\n",
    "    nuis_all.columns = ['pihat', 'muhat0', 'phihat']\n",
    "    data = pd.concat([data.reset_index(), nuis_all.reset_index()], axis=1)\n",
    "    out = pd.concat(out, axis=0).sort_values(by = 'metric')\n",
    "    res = out.groupby('metric').mean()\n",
    "    res['ci_lower'] = None\n",
    "    res['ci_upper'] = None\n",
    "    res = res.reset_index()\n",
    "    \n",
    "    ## Compute P(R_theta != R), the probability the derived predictions differ\n",
    "    ind_df = indicator_df(data, A, R).astype(int)\n",
    "    newvar = ind_df.dot([theta[0], 1 - theta[1], theta[2], 1 - theta[3]])\n",
    "    diff_est = newvar.mean()\n",
    "    res = res.append({'metric': 'prop_differ', 'value': diff_est}, ignore_index = True)\n",
    "    \n",
    "    if ci:\n",
    "        ind_df = indicator_df(data, A, R)\n",
    "        z = scipy.stats.norm.ppf((ci + 1) / 2)\n",
    "        n = data.shape[0]\n",
    "        \n",
    "        ## CIs for risk quantities\n",
    "        risk_est = res.loc[res.metric == 'risk', 'value'].values[0]\n",
    "        change_est = res.loc[res.metric == 'risk_change', 'value'].values[0]\n",
    "        inf_risk_pre = ind_df.dot([0, 1, 0, 1]) * (1 - 2 * data[outcome]) + data[outcome]\n",
    "        inf_risk_post = ind_df.dot(theta) * (1 - 2 * data[outcome]) + data[outcome]\n",
    "        inf_change = inf_risk_post - inf_risk_pre\n",
    "        risk_sd = np.std(inf_risk_post)\n",
    "        change_sd = np.std(inf_change)\n",
    "        lower_risk, upper_risk = ci_prob(risk_est, risk_sd, z, n, ci_scale)\n",
    "        lower_change, upper_change = ci_prob_diff(change_est, change_sd, z, n, ci_scale)\n",
    "        res.loc[res.metric == 'risk', 'ci_lower'] = lower_risk\n",
    "        res.loc[res.metric == 'risk', 'ci_upper'] = upper_risk\n",
    "        res.loc[res.metric == 'risk_change', 'ci_lower'] = lower_change\n",
    "        res.loc[res.metric == 'risk_change', 'ci_upper'] = upper_change\n",
    "        \n",
    "        ## CIs for cFPR quantities\n",
    "        est0 = res.loc[res.metric == 'FPR0', 'value'].values[0]\n",
    "        est1 = res.loc[res.metric == 'FPR1', 'value'].values[0]\n",
    "        est_diff = res.loc[res.metric == 'gap_FPR', 'value'].values[0]\n",
    "        h0 = (1 - data[outcome]) * (1 - data[A])\n",
    "        h1 = (1 - data[outcome]) * data[A]\n",
    "        var_func0 = 1 / h0.mean() * (theta[1] - theta[0]) * (\n",
    "                    data[R] - est0) * h0\n",
    "        var_func1 = 1 / h1.mean() * (theta[3] - theta[2]) * (\n",
    "                    data[R] - est0) * h1\n",
    "        sd0 = np.std(var_func0)\n",
    "        sd1 = np.std(var_func1)\n",
    "        sd_diff = np.std(var_func0 - var_func1)\n",
    "\n",
    "        lower0, upper0 = ci_prob(est0, sd0, z, n, ci_scale)\n",
    "        lower1, upper1 = ci_prob(est1, sd1, z, n, ci_scale)\n",
    "        lower_diff, upper_diff = ci_prob_diff(est_diff, sd_diff, z, n, ci_scale)\n",
    "        res.loc[res.metric == 'FPR0', 'ci_lower'] = lower0\n",
    "        res.loc[res.metric == 'FPR0', 'ci_upper'] = upper0\n",
    "        res.loc[res.metric == 'FPR1', 'ci_lower'] = lower1\n",
    "        res.loc[res.metric == 'FPR1', 'ci_upper'] = upper1\n",
    "        res.loc[res.metric == 'gap_FPR', 'ci_lower'] = lower_diff\n",
    "        res.loc[res.metric == 'gap_FPR', 'ci_upper'] = upper_diff\n",
    "\n",
    "        ## CIs for cFNR quantities\n",
    "        est0 = res.loc[res.metric == 'FNR0', 'value'].values[0]\n",
    "        est1 = res.loc[res.metric == 'FNR1', 'value'].values[0]\n",
    "        est_diff = res.loc[res.metric == 'gap_FNR', 'value'].values[0]\n",
    "        h0 = data[outcome] * (1 - data[A])\n",
    "        h1 = data[outcome] * data[A]\n",
    "        var_func0 = 1 / h0.mean() * (theta[1] - theta[0]) * (\n",
    "                    data[R] - est0) * h0\n",
    "        var_func1 = 1 / h1.mean() * (theta[3] - theta[2]) * (\n",
    "                    data[R] - est0) * h1\n",
    "        var_func_diff = var_func0 - var_func1\n",
    "        sd0 = np.std(var_func0)\n",
    "        sd1 = np.std(var_func1)\n",
    "        sd_diff = np.std(var_func0 - var_func1)\n",
    "\n",
    "        lower0, upper0 = ci_prob(est0, sd0, z, n, ci_scale)\n",
    "        lower1, upper1 = ci_prob(est1, sd1, z, n, ci_scale)\n",
    "        lower_diff, upper_diff = ci_prob_diff(est_diff, sd_diff, z, n, ci_scale)\n",
    "        res.loc[res.metric == 'FNR0', 'ci_lower'] = lower0\n",
    "        res.loc[res.metric == 'FNR0', 'ci_upper'] = upper0\n",
    "        res.loc[res.metric == 'FNR1', 'ci_lower'] = lower1\n",
    "        res.loc[res.metric == 'FNR1', 'ci_upper'] = upper1\n",
    "        res.loc[res.metric == 'gap_FNR', 'ci_lower'] = lower_diff\n",
    "        res.loc[res.metric == 'gap_FNR', 'ci_upper'] = upper_diff\n",
    "        \n",
    "        ## CI for P(R_theta != R)\n",
    "        diff_sd = np.std(newvar)\n",
    "        res.loc[res.metric == 'prop_differ', 'ci_lower'] = diff_est - z*diff_sd/np.sqrt(n)\n",
    "        res.loc[res.metric == 'prop_differ', 'ci_upper'] = diff_est + z*diff_sd/np.sqrt(n)\n",
    "        \n",
    "    return res, out#, nuis_all, data\n",
    "\n",
    "\n",
    "def _metrics_to_df(res):\n",
    "    \"\"\"Convert multi-dim numpy array to a plottable DataFrame.\"\"\"\n",
    "    out = [pd.DataFrame(res[i, :, :]) for i in range(res.shape[0])]\n",
    "    out = pd.concat(out, keys=list(range(len(out))), names=['mc_iter'])\n",
    "    out = out.reset_index().drop(columns='level_1')\n",
    "    out.columns = ['mc_iter', 'metric', 'value', 'ci_lower', 'ci_upper']\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def metrics_to_df(res, n_arr, setting, data_val):\n",
    "    out = [np.apply_along_axis(metrics, 1, rr['theta_arr'], data=data_val,\n",
    "                               outcome='mu0') for rr in res]\n",
    "    out = pd.concat([_metrics_to_df(arr) for arr in out], keys=n_arr)\n",
    "    out = out.reset_index().drop(columns='level_1')\n",
    "    out.columns = ['n', 'mc_iter', 'metric', 'value', 'ci_lower', 'ci_upper']\n",
    "    out['setting'] = setting\n",
    "    out['value'] = pd.to_numeric(out['value'])\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def coverage(metrics_est, metrics_true, simplify=True):\n",
    "    true_dict = metrics_true[['metric', 'value']].set_index('metric').T.to_dict(\n",
    "        'list')\n",
    "    true_vals = metrics_est['metric'].replace(true_dict)\n",
    "    cov = (metrics_est['ci_lower'] <= true_vals) & (\n",
    "                true_vals <= metrics_est['ci_upper'])\n",
    "    out = metrics_est.assign(coverage=cov)\n",
    "    if simplify:\n",
    "        out = out.groupby(['metric', 'n'])[['coverage']].mean()\n",
    "        out = out.unstack().reset_index().rename(columns = {'': 'metric'})\n",
    "        out.columns = out.columns.droplevel(0)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "It's easier to process and visualize the data in R, but I've written the code for generating the post-processed predictor in Python. The workflow is:\n",
    "\n",
    "1. Munge data and generate model matrix in R.\n",
    "2. Read in that processed data and generate post-processed predictor here.\n",
    "3. Save theta values and metrics.\n",
    "4. Use R to visualize theta values and metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for saved data and figures\n",
    "datapath = '../compas_analysis/'\n",
    "outpath = '../compas_analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(os.path.join(datapath, 'compas_general_recidivism.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['released'] = (dat['incarceration_duration'] <= 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_greater_than_45</th>\n",
       "      <th>age_less_than_25</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>crime_factor</th>\n",
       "      <th>score_factor</th>\n",
       "      <th>incarceration_duration</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>released</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   race  gender  age_greater_than_45  age_less_than_25  priors_count  \\\n",
       "0     0       0                    0                 0             0   \n",
       "1     0       0                    0                 1             4   \n",
       "2     1       0                    0                 0            14   \n",
       "3     1       1                    0                 0             0   \n",
       "4     1       0                    0                 0             0   \n",
       "\n",
       "   crime_factor  score_factor  incarceration_duration  two_year_recid  \\\n",
       "0             0             0                      10               1   \n",
       "1             0             0                       1               1   \n",
       "2             0             1                       6               1   \n",
       "3             1             0                       3               0   \n",
       "4             0             0                       1               0   \n",
       "\n",
       "   released  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 'race'\n",
    "X = ['age_greater_than_45', 'age_less_than_25', 'priors_count']\n",
    "R = 'score_factor'\n",
    "D = 'released'\n",
    "Y = 'two_year_recid'\n",
    "\n",
    "learner_pi = RandomForestClassifier(n_estimators=200, min_samples_leaf=10, max_features='sqrt')\n",
    "learner_mu = RandomForestClassifier(n_estimators=200, min_samples_leaf=10, max_features='sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dat, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics over a range of epsilon unfairness bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_arr = []\n",
    "res_arr = []\n",
    "res_folds_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating theta* for epsilon = 0\n",
      "Estimating theta* for epsilon = 0.01\n",
      "Estimating theta* for epsilon = 0.05\n",
      "Estimating theta* for epsilon = 0.1\n",
      "Estimating theta* for epsilon = 0.2\n",
      "Estimating theta* for epsilon = 0.3\n",
      "Estimating theta* for epsilon = 0.4\n",
      "Estimating theta* for epsilon = 0.5\n",
      "Estimating theta* for epsilon = 0.6\n",
      "Estimating theta* for epsilon = 0.7\n",
      "Estimating theta* for epsilon = 0.8\n",
      "Estimating theta* for epsilon = 0.9\n",
      "Estimating theta* for epsilon = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Here using the rewritten fair_derived() and metrics() functions above.\n",
    "for val in vals:\n",
    "    print('Estimating theta* for epsilon = {}'.format(val))\n",
    "    out = fair_derived(train, A, X, R, D, Y, learner_pi, learner_mu, val, val, k = 5)\n",
    "    theta = out.mean(axis=0)\n",
    "    theta_arr.append(theta)\n",
    "    res, res_folds = metrics(theta, test, A, X, R, D, Y, learner_pi,\n",
    "                             learner_mu, k = 5, random_state = random_state)\n",
    "    res_arr.append(res)\n",
    "    res_folds_arr.append(res_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat(res_arr, keys=vals)\n",
    "res = res.reset_index().drop(columns = 'level_1').rename(\n",
    "    columns = {'level_0': 'epsilon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(os.path.join(outpath, 'metrics_post-processed.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(theta_arr).to_csv(os.path.join(outpath, 'theta_array.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fa64a68c6d0>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results: doesn't work with custom CIs. Moving to ggplot.\n",
    "g = sns.FacetGrid(res, col = 'metric', col_order = ['risk', 'gap_FPR', 'gap_FNR'])\n",
    "g.map(sns.pointplot, 'epsilon', 'value', ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Metrics for the input predictor\n",
    "res_in, res_in_arr = metrics([0, 1, 0, 1], test, A, X, R, D, Y, learner_pi,\n",
    "                 learner_mu, k = 5, random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_in.to_csv(os.path.join(outpath, 'metrics_input.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3287384321637972 0.35454545454545455 0.3803524769271119\n"
     ]
    }
   ],
   "source": [
    "# # Observable error rate for input data\n",
    "# err_Y = test_target[R] != test_target[Y]\n",
    "# est = err_Y.mean()\n",
    "# ci_lower = est - 1.96*np.std(err_Y)/np.sqrt(len(err_Y))\n",
    "# ci_upper = est + 1.96*np.std(err_Y)/np.sqrt(len(err_Y))\n",
    "\n",
    "# print(ci_lower, est, ci_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single table for input predictor and post-processed predictor with epsilon = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb_cols(df, name=None):\n",
    "    out = df.value.apply(lambda x: '{0:.2f}'.format(x)) + \\\n",
    "    \"  (\" + df.ci_lower.apply(lambda x: '{0:.2f}'.format(x)) + \", \" +\\\n",
    "    df.ci_upper.apply(lambda x: '{0:.2f}'.format(x)) + \")\"\n",
    "    \n",
    "    out = out.reset_index(drop = True)#.drop(columns = 'index')\n",
    "    if name:\n",
    "        out.name = name\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "res05 = res.loc[res.epsilon == 0.05].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "res05_out = pd.DataFrame({'metric': res_in.reset_index().metric, 'est_S': comb_cols(res_in),\n",
    "                  'est_S_theta': comb_cols(res05)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>est_S</th>\n",
       "      <th>est_S_theta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FNR0</td>\n",
       "      <td>0.30  (0.25, 0.35)</td>\n",
       "      <td>0.36  (0.31, 0.40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FNR1</td>\n",
       "      <td>0.53  (0.46, 0.60)</td>\n",
       "      <td>0.41  (0.35, 0.46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FPR0</td>\n",
       "      <td>0.43  (0.36, 0.49)</td>\n",
       "      <td>0.39  (0.33, 0.45)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FPR1</td>\n",
       "      <td>0.24  (0.18, 0.31)</td>\n",
       "      <td>0.42  (0.37, 0.47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gap_FNR</td>\n",
       "      <td>-0.24  (-0.32, -0.15)</td>\n",
       "      <td>-0.05  (-0.12, 0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gap_FPR</td>\n",
       "      <td>0.18  (0.09, 0.28)</td>\n",
       "      <td>-0.03  (-0.10, 0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>risk</td>\n",
       "      <td>0.36  (0.32, 0.41)</td>\n",
       "      <td>0.39  (0.35, 0.42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>risk_change</td>\n",
       "      <td>0.00  (0.00, 0.00)</td>\n",
       "      <td>0.03  (0.01, 0.04)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prop_differ</td>\n",
       "      <td>0.00  (0.00, 0.00)</td>\n",
       "      <td>0.09  (0.09, 0.09)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        metric                  est_S           est_S_theta\n",
       "0         FNR0     0.30  (0.25, 0.35)    0.36  (0.31, 0.40)\n",
       "1         FNR1     0.53  (0.46, 0.60)    0.41  (0.35, 0.46)\n",
       "2         FPR0     0.43  (0.36, 0.49)    0.39  (0.33, 0.45)\n",
       "3         FPR1     0.24  (0.18, 0.31)    0.42  (0.37, 0.47)\n",
       "4      gap_FNR  -0.24  (-0.32, -0.15)  -0.05  (-0.12, 0.02)\n",
       "5      gap_FPR     0.18  (0.09, 0.28)  -0.03  (-0.10, 0.05)\n",
       "6         risk     0.36  (0.32, 0.41)    0.39  (0.35, 0.42)\n",
       "7  risk_change     0.00  (0.00, 0.00)    0.03  (0.01, 0.04)\n",
       "8  prop_differ     0.00  (0.00, 0.00)    0.09  (0.09, 0.09)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res05_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Need to update pandas to >= 1.1 to use this approach.\n",
    "# custom_dict = {'risk':0, 'risk_change':1, 'FPR0':2, 'FPR1':3, 'FNR0':4, 'FNR1':5,\n",
    "#                'gap_FPR':6, 'gap_FNR':7, 'prop_differ':8}\n",
    "# res05_out.sort_values(by = 'metric', key = lambda x: custom_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1633"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1017 + 616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>released</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1017</td>\n",
       "      <td>2158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>616</td>\n",
       "      <td>1487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "released     0     1\n",
       "race                \n",
       "0         1017  2158\n",
       "1          616  1487"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(dat.race, dat.released)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.2       , 0.85966313, 0.32227249, 1.        ]),\n",
       " array([1.80911292e-10, 8.30623628e-01, 1.56445419e-01, 1.00000000e+00]),\n",
       " array([8.27622273e-10, 9.16505324e-01, 2.31785022e-01, 9.99999999e-01]),\n",
       " array([0.09632576, 0.9761996 , 0.25441309, 1.        ]),\n",
       " array([9.06529596e-10, 9.99999995e-01, 5.44666997e-02, 9.99999998e-01]),\n",
       " array([4.51454483e-10, 9.99999999e-01, 2.07911623e-03, 9.99999997e-01]),\n",
       " array([5.98871075e-09, 9.99999999e-01, 3.67639203e-09, 9.99999992e-01]),\n",
       " array([5.70245697e-09, 9.99999999e-01, 2.01348339e-09, 9.99999995e-01]),\n",
       " array([2.60255912e-09, 1.00000000e+00, 3.22652173e-10, 9.99999996e-01]),\n",
       " array([5.18797809e-09, 9.99999999e-01, 3.21391569e-09, 9.99999989e-01]),\n",
       " array([1.78375154e-09, 1.00000000e+00, 1.54087264e-09, 9.99999994e-01]),\n",
       " array([5.70408153e-09, 9.99999999e-01, 2.74893639e-09, 9.99999985e-01]),\n",
       " array([5.33690331e-09, 1.00000000e+00, 1.08572305e-09, 9.99999992e-01])]"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.27622273e-10, 9.16505324e-01, 2.31785022e-01, 9.99999999e-01])"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_arr[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "res05_out = res05_out.iloc[[6, 7, 2, 3, 0, 1, 4, 5, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outpath, 'metrics_table.csv'), 'w') as file_out:\n",
    "    file_out.write(res05_out.set_index('metric').to_latex(index = True, index_names = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Child welfare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nuisance(train, test, A, X, R, D, Y, learner_pi, learner_mu,\n",
    "                   trunc_pi=0.975):\n",
    "    \"\"\"Train nuisance regressions.\"\"\"\n",
    "    train = train.reset_index()\n",
    "    test = test.reset_index()\n",
    "    # pred_cols = list(itertools.chain.from_iterable([A, X, R]))\n",
    "    pred_cols = [A] + X + [R]\n",
    "    learner_pi.fit(train[pred_cols], train[D])\n",
    "    learner_mu.fit(train.loc[train[D].eq(0), pred_cols],\n",
    "                   train.loc[train[D].eq(0), Y])\n",
    "    if hasattr(learner_pi, 'predict_proba'):\n",
    "        pihat = pd.Series(learner_pi.predict_proba(test[pred_cols])[:, 1],\n",
    "                          name='pihat').clip(upper=trunc_pi)\n",
    "    else:\n",
    "        pihat = pd.Series(learner_pi.predict(test[pred_cols]),\n",
    "                          name='pihat').clip(upper=trunc_pi)\n",
    "    if hasattr(learner_mu, 'predict_proba'):\n",
    "        muhat0 = pd.Series(learner_mu.predict_proba(test[pred_cols])[:, 1],\n",
    "                           name='muhat0')\n",
    "    else:\n",
    "        muhat0 = pd.Series(learner_mu.predict(test[pred_cols]), name='muhat0')\n",
    "    phihat = pd.Series(\n",
    "        (1 - test[D]) / (1 - pihat) * (test[Y] - muhat0) + muhat0,\n",
    "        name='phihat')\n",
    "\n",
    "    out = pd.concat([pihat, muhat0, phihat], axis=1)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def fair_derived(data_nuisance, data_opt, A, X, R, D, Y, learner_pi, learner_mu, epsilon_pos,\n",
    "                 epsilon_neg, outcome='phihat', trunc_pi=0.975, cost1=1, cost2=1):\n",
    "    \"\"\"Optimization with chosen estimators for loss and fairness constraints.\"\"\"\n",
    "    nuis = train_nuisance(data_nuisance, data_opt, A, X, R, D, Y, learner_pi,\n",
    "                          learner_mu, trunc_pi)\n",
    "    data_opt = pd.concat([data_opt.reset_index(), nuis.reset_index()], axis=1)\n",
    "    obj = risk_coefs2(data_opt, A=A, R=R, outcome=outcome, cost1=cost1, cost2=cost2)\n",
    "    fair_pos, fair_neg = fairness_coefs(data_opt, A=A, R=R, outcome=outcome)\n",
    "    theta = optimize(obj, fair_pos, fair_neg, epsilon_pos, epsilon_neg)\n",
    "\n",
    "    out = {'theta': theta, 'risk_coefs': obj,\n",
    "           'fairness_coefs_pos': fair_pos, 'fairness_coefs_neg': fair_neg}\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def metrics(theta, data_nuisance, data_opt, A, X, R, D, Y, learner_pi,\n",
    "            learner_mu, outcome='phihat', ci=0.95, ci_scale='logit'):\n",
    "    \"\"\"Compute risk and fairness metrics wrt Y0.\n",
    "\n",
    "    Args:\n",
    "      data: data over which to compute the metrics.\n",
    "      outcome:\n",
    "        Using phihat as the outcome yields doubly robust estimators.\n",
    "        Using muhat0 as the outcome yields plugin estimators.\n",
    "        Using mu0 as the outcome yields (something close to) the true metrics.\n",
    "      ci: Either None, in which case no CI is computed, or a value in (0, 1).\n",
    "    \"\"\"\n",
    "    nuis = train_nuisance(data_nuisance, data_opt, A, X, R, D, Y, learner_pi, learner_mu)\n",
    "    data_opt = pd.concat([data_opt.reset_index(), nuis.reset_index()], axis=1)\n",
    "    \n",
    "    risk = est_risk(theta, data_opt, A=A, R=R, outcome=outcome, ci=ci, ci_scale=ci_scale)\n",
    "    cFPR = est_cFPR(theta, data_opt, A=A, R=R, outcome=outcome, ci=ci, ci_scale=ci_scale)\n",
    "    cFNR = est_cFNR(theta, data_opt, A=A, R=R, outcome=outcome, ci=ci, ci_scale=ci_scale)\n",
    "\n",
    "    ## Compute P(R_theta != R), the probability the derived predictions differ\n",
    "    ind_df = indicator_df(data_opt, A, R).astype(int)\n",
    "    newvar = ind_df.dot([theta[0], 1 - theta[1], theta[2], 1 - theta[3]])\n",
    "    diff_est = newvar.mean()           \n",
    "    ## CI for P(R_theta != R)\n",
    "    n = data_opt.shape[0]\n",
    "    z = scipy.stats.norm.ppf((ci + 1) / 2)\n",
    "    diff_sd = np.std(newvar)\n",
    "    ci_lower = diff_est - z*diff_sd/np.sqrt(n)\n",
    "    ci_upper = diff_est + z*diff_sd/np.sqrt(n)\n",
    "    prop_differ = pd.DataFrame({'metric': 'prop_differ', 'value': diff_est,\n",
    "                              'ci_lower': ci_lower, 'ci_upper': ci_upper},\n",
    "                             index = [0])\n",
    "        \n",
    "    out = pd.concat([risk, cFPR, cFNR, prop_differ])\n",
    "\n",
    "    return out\n",
    "\n",
    "#########################\n",
    "#### Risk functions #####\n",
    "#########################\n",
    "\n",
    "def risk_coef2(data, a, r, A='A', R='R', outcome='phihat', cost1=1, cost2=1):\n",
    "    \"\"\"Compute the loss coefficient for a single row, for given values\n",
    "    A = a, R = r.\n",
    "\n",
    "    Using phihat as the outcome yields a doubly robust estimator.\n",
    "    Using muhat0 as the outcome yields a plugin estimator.\n",
    "    Using mu0 as the outcome yields (something close to) the ``true'' loss\n",
    "    coefficient.\n",
    "    \"\"\"\n",
    "    out = (((data[A] == a) & (data[R] == r)) * (cost1 - (cost1 + cost2) * data[outcome])).mean()\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def risk_coefs2(data, A='A', R='R', outcome='phihat', cost1=1, cost2=1):\n",
    "    \"\"\"Compute the loss coefficients.\n",
    "\n",
    "    Using phihat as the outcome yields a doubly robust estimator.\n",
    "    Using muhat0 as the outcome yields a plugin estimator.\n",
    "    Using mu0 as the outcome yields (something close to) the ``true'' loss\n",
    "    coefficients.\n",
    "    \"\"\"\n",
    "    ar_list = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "    coefs = [risk_coef2(data, a, r, A, R, outcome, cost1, cost2) for a, r in ar_list]\n",
    "    out = np.array(coefs).clip(-1, 1)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for saved data\n",
    "datapath = '../child_welfare_analysis/'\n",
    "outpath = '../child_welfare_analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wel_train = pd.read_csv(os.path.join(datapath, 'child_welfare_train.csv'))\n",
    "wel_test = pd.read_csv(os.path.join(datapath, 'child_welfare_test.csv'))\n",
    "\n",
    "wel_train_nuis = wel_train.loc[wel_train.partition2 == 'nuisance']\n",
    "wel_train_target = wel_train.loc[wel_train.partition2 == 'target']\n",
    "\n",
    "# wel_train = wel_train.assign(R_obs50 = (wel_train.muhat >= 0.5).astype(int),\n",
    "#                             R50 = (wel_train.muhat0 >= 0.5).astype(int))\n",
    "# wel_test = wel_test.assign(R_obs50 = (wel_test.muhat >= 0.5).astype(int),\n",
    "#                           R50 = (wel_test.muhat0 >= 0.5).astype(int))\n",
    "\n",
    "wel_test_nuis = wel_test.loc[wel_test.partition2 == 'nuisance']\n",
    "wel_test_target = wel_test.loc[wel_test.partition2 == 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 'race'\n",
    "with open(os.path.join(datapath, 'predictors.txt'), 'r') as file_in:\n",
    "    X = file_in.read().rstrip('\\n').split('\\t')\n",
    "R = 'R'  # counterfactual model\n",
    "# R = 'R_obs'  # observational model\n",
    "# R = 'R50'\n",
    "D = 'SCREEN_IN'\n",
    "Y = 'REREF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_pi_train = RandomForestClassifier(n_estimators=200, min_samples_leaf=10, max_features='sqrt')\n",
    "learner_pi_test = RandomForestClassifier(n_estimators=200, min_samples_leaf=10, max_features='sqrt')\n",
    "learner_mu_train = RandomForestClassifier(n_estimators=200, min_samples_leaf=10, max_features='sqrt')\n",
    "learner_mu_test = RandomForestClassifier(n_estimators=200, min_samples_leaf=10, max_features='sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_in = metrics([0, 1, 0, 1], wel_test_nuis, wel_test_target, A, X, R, D, Y,\n",
    "                    learner_pi_test, learner_mu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>risk</td>\n",
       "      <td>0.312333</td>\n",
       "      <td>0.300707</td>\n",
       "      <td>0.324200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>risk_change</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FPR0</td>\n",
       "      <td>0.023830</td>\n",
       "      <td>0.017651</td>\n",
       "      <td>0.032102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FPR1</td>\n",
       "      <td>0.043346</td>\n",
       "      <td>0.034826</td>\n",
       "      <td>0.053833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gap_FPR</td>\n",
       "      <td>-0.019515</td>\n",
       "      <td>-0.031344</td>\n",
       "      <td>-0.007682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FNR0</td>\n",
       "      <td>0.954080</td>\n",
       "      <td>0.861182</td>\n",
       "      <td>0.985833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FNR1</td>\n",
       "      <td>0.862065</td>\n",
       "      <td>0.803065</td>\n",
       "      <td>0.905470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gap_FNR</td>\n",
       "      <td>0.092015</td>\n",
       "      <td>0.013031</td>\n",
       "      <td>0.169858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prop_differ</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        metric     value  ci_lower  ci_upper\n",
       "0         risk  0.312333  0.300707  0.324200\n",
       "1  risk_change  0.000000  0.000000  0.000000\n",
       "0         FPR0  0.023830  0.017651  0.032102\n",
       "1         FPR1  0.043346  0.034826  0.053833\n",
       "2      gap_FPR -0.019515 -0.031344 -0.007682\n",
       "0         FNR0  0.954080  0.861182  0.985833\n",
       "1         FNR1  0.862065  0.803065  0.905470\n",
       "2      gap_FNR  0.092015  0.013031  0.169858\n",
       "0  prop_differ  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics for the counterfactual model\n",
    "metrics_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>risk</td>\n",
       "      <td>0.319521</td>\n",
       "      <td>0.307816</td>\n",
       "      <td>0.331457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>risk_change</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.014671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FPR0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FPR1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gap_FPR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FNR0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FNR1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gap_FNR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        metric     value  ci_lower  ci_upper\n",
       "0         risk  0.319521  0.307816  0.331457\n",
       "1  risk_change  0.007722  0.000772  0.014671\n",
       "0         FPR0  0.000000  0.000000  0.000000\n",
       "1         FPR1  0.000000  0.000000  0.000000\n",
       "2      gap_FPR  0.000000  0.000000  0.000000\n",
       "0         FNR0  1.000000  1.000000  1.000000\n",
       "1         FNR1  1.000000  1.000000  1.000000\n",
       "2      gap_FNR  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics for the base rate model\n",
    "metrics0 = metrics([0, 0, 0, 0], wel_test_nuis, wel_test_target, A, X, R, D, Y,\n",
    "                    learner_pi_test, learner_mu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating for epsilon = 0\n",
      "Estimating for epsilon = 0.01\n",
      "Estimating for epsilon = 0.05\n",
      "Estimating for epsilon = 0.1\n"
     ]
    }
   ],
   "source": [
    "# Using fair_derived() and metrics() functions as rewritten above.\n",
    "vals = [0, 0.01, 0.05, 0.10]\n",
    "out_arr = []\n",
    "for val in vals:\n",
    "    print(\"Estimating for epsilon = {}\".format(val))\n",
    "    out = fair_derived(wel_train_nuis, wel_train_target, A, X, R, D, Y,\n",
    "                   learner_pi_train, learner_mu_train, val, val)\n",
    "    out_arr.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>REREF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th>R</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.305147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.519481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0.285436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           REREF\n",
       "race R          \n",
       "0    0  0.305147\n",
       "     1  0.519481\n",
       "1    0  0.285436\n",
       "     1  0.600000"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wel_test.loc[wel_test.SCREEN_IN == 0].groupby([A, R])[['REREF']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10385, 1059)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wel_train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.001,  1.   , -0.   ,  0.828]),\n",
       " array([0.  , 1.  , 0.  , 0.96]),\n",
       " array([0., 1., 0., 1.]),\n",
       " array([0., 1., 0., 1.])]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_arr = [np.round(out['theta'], 3) for out in out_arr]\n",
    "theta_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>risk</td>\n",
       "      <td>0.312344</td>\n",
       "      <td>0.300882</td>\n",
       "      <td>0.324040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>risk_change</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.002644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FPR0</td>\n",
       "      <td>0.024452</td>\n",
       "      <td>0.018408</td>\n",
       "      <td>0.032413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FPR1</td>\n",
       "      <td>0.035611</td>\n",
       "      <td>0.028666</td>\n",
       "      <td>0.044162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gap_FPR</td>\n",
       "      <td>-0.011159</td>\n",
       "      <td>-0.021506</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FNR0</td>\n",
       "      <td>0.951856</td>\n",
       "      <td>0.860460</td>\n",
       "      <td>0.984470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FNR1</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.835912</td>\n",
       "      <td>0.921033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gap_FNR</td>\n",
       "      <td>0.066689</td>\n",
       "      <td>-0.006153</td>\n",
       "      <td>0.138828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        metric     value  ci_lower  ci_upper\n",
       "0         risk  0.312344  0.300882  0.324040\n",
       "1  risk_change  0.001652  0.000660  0.002644\n",
       "0         FPR0  0.024452  0.018408  0.032413\n",
       "1         FPR1  0.035611  0.028666  0.044162\n",
       "2      gap_FPR -0.011159 -0.021506 -0.000809\n",
       "0         FNR0  0.951856  0.860460  0.984470\n",
       "1         FNR1  0.885167  0.835912  0.921033\n",
       "2      gap_FNR  0.066689 -0.006153  0.138828"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slightly improves the cFNR gap. Maybe.\n",
    "metrics(out_arr[0]['theta'], wel_test_nuis, wel_test_target, A, X, R, D, Y,\n",
    "                    learner_pi_test, learner_mu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating for cost ratio = 0.3333333333333333\n",
      "Estimating for cost ratio = 0.4\n",
      "Estimating for cost ratio = 0.5\n",
      "Estimating for cost ratio = 0.5714285714285714\n",
      "Estimating for cost ratio = 0.6666666666666666\n",
      "Estimating for cost ratio = 0.8\n",
      "Estimating for cost ratio = 1\n",
      "Estimating for cost ratio = 1.25\n",
      "Estimating for cost ratio = 1.5\n",
      "Estimating for cost ratio = 1.75\n",
      "Estimating for cost ratio = 2\n",
      "Estimating for cost ratio = 2.5\n",
      "Estimating for cost ratio = 3\n"
     ]
    }
   ],
   "source": [
    "## Try optimizing with differential error costs -- higher cost for false negatives\n",
    "val = 0.01\n",
    "out_arr = []\n",
    "cost_ratios = [1/3, 1/2.5, 1/2, 1/1.75, 1/1.5, 1/1.25, 1, 1.25, 1.5, 1.75, 2, 2.5, 3] \n",
    "for cc in cost_ratios:\n",
    "    print(\"Estimating for cost ratio = {}\".format(cc))\n",
    "    out = fair_derived(wel_train_nuis, wel_train_target, A, X, R, D, Y,\n",
    "                   learner_pi_train, learner_mu_train, val, val, cost1=1, cost2=cc)\n",
    "    out_arr.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0.]),\n",
       " array([0.   , 0.137, 0.   , 0.   ]),\n",
       " array([0.   , 1.   , 0.   , 0.726]),\n",
       " array([0.  , 1.  , 0.  , 0.94]),\n",
       " array([0.   , 1.   , 0.   , 0.934]),\n",
       " array([0.   , 1.   , 0.   , 0.939]),\n",
       " array([0.006, 1.   , 0.   , 1.   ]),\n",
       " array([0.007, 1.   , 0.   , 1.   ]),\n",
       " array([0.006, 1.   , 0.   , 1.   ]),\n",
       " array([1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1.])]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_arr = [np.round(out['theta'], 3) for out in out_arr]\n",
    "theta_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(theta_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.vstack(theta_arr)\n",
    "# pd.concat(theta_arr, keys=cost_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = pd.DataFrame(thetas).assign(cost_ratio = cost_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas.columns = ['theta1', 'theta2', 'theta3', 'theta4', 'cost_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas.to_csv(os.path.join('../child_welfare_analysis/', 'thetas_cost_sensitive.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating for cost ratio = 0.25\n",
      "Estimating for cost ratio = 0.3535533905932738\n",
      "Estimating for cost ratio = 0.5\n",
      "Estimating for cost ratio = 0.7071067811865476\n",
      "Estimating for cost ratio = 1\n",
      "Estimating for cost ratio = 1.4142135623730951\n",
      "Estimating for cost ratio = 2\n",
      "Estimating for cost ratio = 2.8284271247461903\n",
      "Estimating for cost ratio = 4\n"
     ]
    }
   ],
   "source": [
    "## Try optimizing with differential error costs -- higher cost for false negatives\n",
    "# vals = [0, 0.01, 0.05, 0.10, 1]\n",
    "val = 0.01\n",
    "out_arr = []\n",
    "cost_ratios = [2**x for x in [-2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2]]\n",
    "for cc in cost_ratios:\n",
    "    print(\"Estimating for cost ratio = {}\".format(cc))\n",
    "    out = fair_derived(wel_train_nuis, wel_train_target, A, X, R, D, Y,\n",
    "                   learner_pi_train, learner_mu_train, val, val, cost1=1, cost2=cc)\n",
    "    out_arr.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating for cost ratio = 0.6\n",
      "[0.    1.    0.    0.701]\n",
      "[0.007 1.    0.    1.   ]\n",
      "Estimating for cost ratio = 0.7\n",
      "[0.    1.    0.    0.933]\n",
      "[0.007 1.    0.    1.   ]\n",
      "Estimating for cost ratio = 0.8\n",
      "[0.    1.    0.    0.932]\n",
      "[0.    1.    0.    0.926]\n",
      "Estimating for cost ratio = 0.9\n",
      "[0.    1.    0.    0.933]\n",
      "[0.    1.    0.    0.932]\n"
     ]
    }
   ],
   "source": [
    "val = 0.01\n",
    "out_arr = []\n",
    "cost_ratios = [0.6, 0.7, 0.8, 0.9]\n",
    "for cc in cost_ratios:\n",
    "    print(\"Estimating for cost ratio = {}\".format(cc))\n",
    "    out = fair_derived(wel_train_nuis, wel_train_target, A, X, R, D, Y,\n",
    "                   learner_pi_train, learner_mu_train, val, val, cost1=1, cost2=cc)\n",
    "    print(np.round(out['theta'], 3))\n",
    "    out = fair_derived(wel_train_nuis, wel_train_target, A, X, R, D, Y,\n",
    "                   learner_pi_train, learner_mu_train, val, val, cost1=cc, cost2=1)\n",
    "    print(np.round(out['theta'], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0.]),\n",
       " array([0.   , 1.   , 0.   , 0.935]),\n",
       " array([0.   , 1.   , 0.   , 0.947]),\n",
       " array([0.007, 1.   , 0.   , 1.   ]),\n",
       " array([0.007, 1.   , 0.   , 1.   ]),\n",
       " array([1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1.])]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_arr = [np.round(out['theta'], 3) for out in out_arr]\n",
    "theta_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(theta_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>risk</td>\n",
       "      <td>0.314012</td>\n",
       "      <td>0.302506</td>\n",
       "      <td>0.325751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>risk_change</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.002532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FPR0</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.018947</td>\n",
       "      <td>0.033166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FPR1</td>\n",
       "      <td>0.036561</td>\n",
       "      <td>0.029387</td>\n",
       "      <td>0.045405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gap_FPR</td>\n",
       "      <td>-0.011468</td>\n",
       "      <td>-0.022080</td>\n",
       "      <td>-0.000854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FNR0</td>\n",
       "      <td>0.952056</td>\n",
       "      <td>0.861404</td>\n",
       "      <td>0.984483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FNR1</td>\n",
       "      <td>0.884998</td>\n",
       "      <td>0.834854</td>\n",
       "      <td>0.921352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gap_FNR</td>\n",
       "      <td>0.067057</td>\n",
       "      <td>-0.005971</td>\n",
       "      <td>0.139374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        metric     value  ci_lower  ci_upper\n",
       "0         risk  0.314012  0.302506  0.325751\n",
       "1  risk_change  0.001576  0.000619  0.002532\n",
       "0         FPR0  0.025093  0.018947  0.033166\n",
       "1         FPR1  0.036561  0.029387  0.045405\n",
       "2      gap_FPR -0.011468 -0.022080 -0.000854\n",
       "0         FNR0  0.952056  0.861404  0.984483\n",
       "1         FNR1  0.884998  0.834854  0.921352\n",
       "2      gap_FNR  0.067057 -0.005971  0.139374"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(out_arr[0]['theta'], wel_test_nuis, wel_test_target, A, X, R, D, Y,\n",
    "                    learner_pi_test, learner_mu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get combined table for input predictor and the predictor for theta = [0, 0, 0, 0]\n",
    "res_out = pd.DataFrame({'metric': metrics_in.reset_index().metric, 'est_S': comb_cols(metrics_in),\n",
    "                  'est_S_0': comb_cols(metrics0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>est_S</th>\n",
       "      <th>est_S_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>risk</td>\n",
       "      <td>0.31  (0.30, 0.32)</td>\n",
       "      <td>0.32  (0.31, 0.33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>risk_change</td>\n",
       "      <td>0.00  (0.00, 0.00)</td>\n",
       "      <td>0.01  (0.00, 0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FPR0</td>\n",
       "      <td>0.02  (0.02, 0.03)</td>\n",
       "      <td>0.00  (0.00, 0.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FPR1</td>\n",
       "      <td>0.04  (0.03, 0.05)</td>\n",
       "      <td>0.00  (0.00, 0.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FNR0</td>\n",
       "      <td>0.95  (0.86, 0.99)</td>\n",
       "      <td>1.00  (1.00, 1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FNR1</td>\n",
       "      <td>0.86  (0.80, 0.91)</td>\n",
       "      <td>1.00  (1.00, 1.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gap_FPR</td>\n",
       "      <td>-0.02  (-0.03, -0.01)</td>\n",
       "      <td>0.00  (0.00, 0.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gap_FNR</td>\n",
       "      <td>0.09  (0.01, 0.17)</td>\n",
       "      <td>0.00  (0.00, 0.00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prop_differ</td>\n",
       "      <td>0.00  (0.00, 0.00)</td>\n",
       "      <td>0.05  (0.05, 0.06)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        metric                  est_S             est_S_0\n",
       "0         risk     0.31  (0.30, 0.32)  0.32  (0.31, 0.33)\n",
       "1  risk_change     0.00  (0.00, 0.00)  0.01  (0.00, 0.01)\n",
       "2         FPR0     0.02  (0.02, 0.03)  0.00  (0.00, 0.00)\n",
       "3         FPR1     0.04  (0.03, 0.05)  0.00  (0.00, 0.00)\n",
       "5         FNR0     0.95  (0.86, 0.99)  1.00  (1.00, 1.00)\n",
       "6         FNR1     0.86  (0.80, 0.91)  1.00  (1.00, 1.00)\n",
       "4      gap_FPR  -0.02  (-0.03, -0.01)  0.00  (0.00, 0.00)\n",
       "7      gap_FNR     0.09  (0.01, 0.17)  0.00  (0.00, 0.00)\n",
       "8  prop_differ     0.00  (0.00, 0.00)  0.05  (0.05, 0.06)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_out = res_out.iloc[[0, 1, 2, 3, 5, 6, 4, 7, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outpath, 'metrics_table.csv'), 'w') as file_out:\n",
    "    file_out.write(res_out.set_index('metric').to_latex(index = True, index_names = False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
